{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42300bd8-6f80-4b09-a379-d2427236f23c",
   "metadata": {},
   "source": [
    "Q1. **Filter Method in Feature Selection:**\n",
    "   - **Definition:** The filter method is a feature selection technique that evaluates the relevance of features based on certain statistical measures or scoring criteria. It doesn't involve training a model but relies on characteristics of the data itself.\n",
    "   - **How it works:** Features are evaluated independently of the machine learning model. Common techniques include correlation, mutual information, and statistical tests like ANOVA. Features are ranked or assigned scores, and a predefined threshold is used to select the top-ranked features.\n",
    "\n",
    "Q2. **Wrapper Method vs. Filter Method:**\n",
    "   - **Wrapper Method:** It involves training a machine learning model and assessing different subsets of features based on model performance. Examples include forward selection, backward elimination, and recursive feature elimination.\n",
    "   - **Differences:**\n",
    "     - Wrapper methods use the predictive performance of a specific machine learning algorithm to evaluate feature subsets.\n",
    "     - Filter methods rely on intrinsic properties of the data, irrespective of a specific model.\n",
    "     - Wrapper methods are computationally more expensive as they involve training multiple models.\n",
    "\n",
    "Q3. **Embedded Feature Selection Methods:**\n",
    "   - **Definition:** Embedded methods incorporate feature selection as part of the model training process.\n",
    "   - **Common Techniques:**\n",
    "     - **LASSO (Least Absolute Shrinkage and Selection Operator):** Penalizes the absolute size of regression coefficients, encouraging sparsity.\n",
    "     - **Tree-based methods (e.g., Random Forest, Gradient Boosting):** Automatically select features during the tree-building process.\n",
    "     - **Regularized regression models:** Integrate penalty terms to control feature importance.\n",
    "\n",
    "Q4. **Drawbacks of Filter Method:**\n",
    "   - **Independence Assumption:** Filter methods evaluate features independently and might miss interactions between features.\n",
    "   - **Static Thresholds:** Setting a fixed threshold may lead to overlooking relevant features or including irrelevant ones.\n",
    "   - **Ignores Model Information:** Filter methods don't consider the impact of features on the model's performance.\n",
    "\n",
    "Q5. **When to Use Filter Method over Wrapper Method:**\n",
    "   - **Large Datasets:** Filter methods are computationally less expensive, making them suitable for large datasets.\n",
    "   - **Quick Exploration:** If a quick exploration of feature importance is needed without training multiple models.\n",
    "\n",
    "Q6. **Using Filter Method for Telecom Customer Churn Model:**\n",
    "   - **Steps:**\n",
    "     1. **Correlation Analysis:** Identify features correlated with the target variable (churn).\n",
    "     2. **Statistical Tests:** Use statistical tests like chi-square or ANOVA to evaluate the significance of categorical and numerical features.\n",
    "     3. **Mutual Information:** Assess the information gain between each feature and the target variable.\n",
    "\n",
    "Q7. **Using Embedded Method for Soccer Match Prediction:**\n",
    "   - **Steps:**\n",
    "     1. **Tree-based Models:** Employ Random Forest or Gradient Boosting models that inherently provide feature importance scores.\n",
    "     2. **Regularized Models:** Utilize models like LASSO regression to penalize less informative features.\n",
    "     3. **Feature Importance Analysis:** Analyze feature importance plots generated by the chosen algorithm.\n",
    "\n",
    "Q8. **Using Wrapper Method for House Price Prediction:**\n",
    "   - **Steps:**\n",
    "     1. **Subset Evaluation:** Start with a subset of features.\n",
    "     2. **Model Training:** Train the model with the subset and evaluate performance.\n",
    "     3. **Feature Subset Adjustment:** Iteratively add or remove features based on model performance.\n",
    "     4. **Cross-Validation:** Validate the final feature subset using cross-validation for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ce362-9279-4e1c-a958-2851cc798d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
